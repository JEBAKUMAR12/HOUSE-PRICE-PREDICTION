{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JEBAKUMAR12/HOUSE-PRICE-PREDICTION/blob/main/house_eda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGQ6qcBuDXJ5"
      },
      "source": [
        "## <font color='#ff0000'> **House Price Predication** </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOLeTzZYDXJ7"
      },
      "source": [
        "The dataset contains information about houses in Bengaluru, India, with the following features:\n",
        "\n",
        "**Categorical Features:**\n",
        "\n",
        "*   `area_type`: Type of area (e.g., Super built-up area, Plot area, Built-up area, Carpet area).\n",
        "*   `availability`: Date or status of availability.\n",
        "*   `location`: Neighborhood or area of the house.\n",
        "*   `size`: Number of bedrooms or BHK (e.g., 2 BHK, 3 Bedroom).\n",
        "*  `society`: Society Name of the apartment\n",
        "\n",
        "**Numerical Features:**\n",
        "\n",
        "*   `total_sqft`: Total area in square feet (can be a single value or a range).\n",
        "*   `bath`: Number of bathrooms.\n",
        "*   `balcony`: Number of balconies.\n",
        "*   `price`: Price of the house in the Indian currency unit (Lakhs).\n",
        "\n",
        "**Key Characteristics:**\n",
        "\n",
        "*   **Mix of Area Types:** The dataset includes various types of areas: Super built-up, Plot, Built-up, and Carpet areas.\n",
        "*   **Availability Patterns:** Properties are available at various times, with \"Ready To Move\" as the most frequent status. Some are marked with specific dates.\n",
        "*  **Varied Locations:** The dataset covers a diverse range of locations across Bengaluru.\n",
        "*   **Different Property Sizes:** The dataset contains properties from 1 RK to 10+ bedroom houses.\n",
        "*   **Presence of Missing Data:** The dataset contains several missing values across the features\n",
        "*   **Inconsistencies in Size values:** The 'size' feature includes 'Bedroom' or 'BHK'\n",
        "*   **Inconsistencies in total_sqft values:** The values in total_sqft include a range (example: \"2100-2850\")\n",
        "*   **Inconsistencies in price values:** prices are in lakhs\n",
        "\n",
        "The dataset appears to represent a mix of various property types (apartments, houses) with a wide variety of size, location, and price, presenting an interesting challenge for analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0UTH0CyDXJ8"
      },
      "source": [
        "### **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZgdgRWW3DXJ8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZRuma56DXJ9"
      },
      "source": [
        "### **Import Dateset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "notebookRunGroups": {
          "groupValue": "2"
        },
        "id": "DO0FrWQFDXJ9"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../data/Bengaluru_House_Data.csv')\n",
        "df.head(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZA6XSdigDXJ9"
      },
      "source": [
        "### <font color=\"#00CEFF\"> **Exploratory data analysis (EDA)** </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbril1QlDXJ9"
      },
      "source": [
        "##### **Summary of Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDSiE-j5DXJ-"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03opahhbDXJ-"
      },
      "source": [
        "#### Number of Rows and column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olTLg79kDXJ-"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH4aimwmDXJ-"
      },
      "source": [
        "##### **Statistical Summary of Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iBr4z8ODXJ-"
      },
      "outputs": [],
      "source": [
        "df.describe() # only Numeric Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwUQ0lZaDXJ-"
      },
      "source": [
        "\n",
        "**1.  Count:**\n",
        "\n",
        "*   `bath`: 13,247\n",
        "*   `balcony`: 12,711\n",
        "*   `price`: 13,320\n",
        "\n",
        "This indicates the number of non-missing values for each feature in the dataset. It also shows that the 'balcony' feature has the most missing values with only 12711 values.\n",
        "\n",
        "**2. Mean:**\n",
        "\n",
        "*   `bath`:  2.69\n",
        "*  `balcony`: 1.58\n",
        "*   `price`: 112.57\n",
        "\n",
        "This is the average value for each feature. It shows that on average the dataset properties have 2.69 bathrooms, 1.58 balconies and price at approximately 112.57.\n",
        "\n",
        "**3. Standard Deviation (std):**\n",
        "\n",
        "*   `bath`: 1.34\n",
        "*   `balcony`: 0.82\n",
        "*   `price`: 148.97\n",
        "\n",
        "Standard deviation is a measure of the dispersion or spread of the data. Higher values indicate a wider spread. The price feature displays a high spread as compared to the bath and balcony features.\n",
        "\n",
        "**4. Minimum (min):**\n",
        "\n",
        "*   `bath`: 1.00\n",
        "*   `balcony`: 0.00\n",
        "*   `price`: 8.00\n",
        "\n",
        "These are the smallest values in the dataset for each of these features respectively. It shows the minimum number of bathrooms, balcony or price in the dataset.\n",
        "\n",
        "**5. 25th Percentile:**\n",
        "\n",
        "*   `bath`: 2.00\n",
        "*   `balcony`: 1.00\n",
        "*  `price`: 50.00\n",
        "\n",
        "This means that 25% of the houses have 2 bathrooms, 1 balcony and a price less than or equal to 50\n",
        "\n",
        "**6. 50th Percentile (Median):**\n",
        "\n",
        "*   `bath`: 2.00\n",
        "*   `balcony`: 2.00\n",
        "*   `price`: 72.00\n",
        "\n",
        "This is the middle value of each of the features. Half of the houses have 2 bathrooms, 2 balconies and half have price less than or equal to 72.\n",
        "\n",
        "**7. 75th Percentile:**\n",
        "\n",
        "*   `bath`: 3.00\n",
        "*   `balcony`: 2.00\n",
        "*   `price`: 120.00\n",
        "\n",
        "This shows that 75% of the properties have 3 bathrooms, 2 balconies, and a price less than or equal to 120\n",
        "\n",
        "**8. Maximum (max):**\n",
        "\n",
        "*   `bath`: 40.00\n",
        "*   `balcony`: 3.00\n",
        "*   `price`: 3600.00\n",
        "\n",
        "These are the largest values in the dataset for each feature. There are few outliers with as high as 40 bathrooms and price as high as 3600\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGhkRzoLDXJ_"
      },
      "outputs": [],
      "source": [
        "# df.describe(include=['object'])\n",
        "df.describe(exclude=['number']).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-VSfjzlDXJ_"
      },
      "source": [
        "#### Check missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6eIk1SzDXJ_"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kqCQ2UuDXJ_"
      },
      "source": [
        "#### Drop unwanted Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0J4zRFeDXJ_"
      },
      "outputs": [],
      "source": [
        "df1 = df.drop(['area_type','availability','society','balcony'], axis=1)\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3-YniFbDXJ_"
      },
      "outputs": [],
      "source": [
        "df1.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R-8p9cbDXJ_"
      },
      "source": [
        "<p> Missing values is less only, compared to the Total number of data set. so drop the missing rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ois5I-lPDXJ_"
      },
      "outputs": [],
      "source": [
        "df2 = df1.dropna()\n",
        "df2.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvp5nQcPDXJ_"
      },
      "source": [
        "#### Analyse Data using groupby()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yy6xpNDLDXJ_"
      },
      "outputs": [],
      "source": [
        "df2.groupby('size')['total_sqft'].agg('count').sort_values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS7kVk3iDXJ_"
      },
      "source": [
        "#### Apply Naming conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoR9iJ_3DXKA"
      },
      "outputs": [],
      "source": [
        "df2['size'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R94FnoPDDXKA"
      },
      "outputs": [],
      "source": [
        "df2['bhk']=df2['size'].apply(lambda x : int(x.split(' ')[0]))\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2V4txROsDXKA"
      },
      "outputs": [],
      "source": [
        "df2['bhk'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLbIn3M9DXKA"
      },
      "outputs": [],
      "source": [
        "df2[df2['bhk']>20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axbQQDzSDXKA"
      },
      "source": [
        "find problematic entries in a column that is expected to contain numeric values.\n",
        "1. Non-numeric strings like \"2000 - 3000\", \"N/A\", or \"unknown\".\n",
        "2. Mixed data types in the column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9DyAPmGDXKA"
      },
      "outputs": [],
      "source": [
        "df2['total_sqft'].dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxvc-TbQDXKA"
      },
      "outputs": [],
      "source": [
        "def is_float(x):\n",
        "    try:\n",
        "        float(x)\n",
        "    except:\n",
        "        return False\n",
        "    return True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySHhuPh2DXKA"
      },
      "source": [
        "##### ~ (Tilde Operator):\n",
        "<p>It converts True to False and vice versa.So, ~df2['total_sqft'].apply(is_float)  identifies rows where total_sqft cannot be converted to a float. </p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrIM9hSgDXKA"
      },
      "outputs": [],
      "source": [
        "df2[~df2['total_sqft'].apply(is_float)].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8mdXmyxDXKA"
      },
      "outputs": [],
      "source": [
        "df2.loc[410]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xV-wwIDDXKA"
      },
      "outputs": [],
      "source": [
        "# df2 = df2.drop(['size'],axis=1)\n",
        "# df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyOVzEbiDXKA"
      },
      "outputs": [],
      "source": [
        "# def convert_sqrt_num(x):\n",
        "#     tokens = x.split('-')\n",
        "#     if len(tokens) == 2:\n",
        "#         return (float(tokens[0])+float(tokens[1]))/2\n",
        "#     try:\n",
        "#         numeric_part = ''.join(c for c in x if c.isdigit() or c == '.')\n",
        "#         return float(numeric_part)\n",
        "#         # return float(x)\n",
        "#     except:\n",
        "#         return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ni73k2oXDXKA"
      },
      "outputs": [],
      "source": [
        "def convert_sqrt_num(x):\n",
        "    try:\n",
        "        # Handle ranges (e.g., '1015 - 1540')\n",
        "        if '-' in x:\n",
        "            tokens = x.split('-')\n",
        "            return (float(tokens[0].strip()) + float(tokens[1].strip())) / 2\n",
        "\n",
        "        # Remove non-numeric characters (e.g., 'Sq. Meter', 'Sq. Yards')\n",
        "        for unit in ['Sq. Meter', 'Sq. Yards', 'Perch', 'Acres', 'Guntha', 'Cents', 'Grounds']:\n",
        "            x = x.replace(unit, '')\n",
        "\n",
        "        # Convert cleaned string to float\n",
        "        return float(x.strip())\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing '{x}': {e}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0U_Elp-ODXKB"
      },
      "outputs": [],
      "source": [
        "df3 = df2.copy()\n",
        "# print(df3.loc[410])\n",
        "# print(df3.loc[188])\n",
        "# print(df3.loc[648])\n",
        "# print(\"---------\")\n",
        "\n",
        "df3['total_sqft']= df3['total_sqft'].apply(convert_sqrt_num)\n",
        "# df3.head(3)\n",
        "\n",
        "\n",
        "# print(df3.loc[410])\n",
        "# print(df3.loc[188])\n",
        "# print(df3.loc[648])\n",
        "# print(df3['total_sqft'].dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrW9YxGHDXKB"
      },
      "outputs": [],
      "source": [
        "df3[~df3['total_sqft'].apply(is_float)].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2bCtmxKDXKC"
      },
      "source": [
        "#### Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a05jfK_DXKC"
      },
      "outputs": [],
      "source": [
        "df4 = df3.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT9QfttJDXKC"
      },
      "source": [
        "##### Explore the Location column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjn8tAZIDXKC"
      },
      "outputs": [],
      "source": [
        "print(df4.location.unique())\n",
        "print(len(df4.location.unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kawTAUspDXKC"
      },
      "source": [
        "1304 unique values is just large, this called curse of Dimensionality or high dimensionality problem. using 'other' in unique values, we reduce the dimensionality problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFj6yxefDXKC"
      },
      "source": [
        "**Strip extra space from the location**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ds3uiDkDXKC"
      },
      "outputs": [],
      "source": [
        "df4.location = df4.location.apply(lambda x : x.strip())\n",
        "len(df4.location.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_M6zwgVDXKC"
      },
      "outputs": [],
      "source": [
        "location_stats = df4.groupby('location')['location'].agg('count').sort_values(ascending=False)\n",
        "location_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GawAtQrUDXKC"
      },
      "outputs": [],
      "source": [
        "location_stats_less_than_10 = location_stats[location_stats<=10]\n",
        "len(location_stats[location_stats<=10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y3XEPDmDXKC"
      },
      "outputs": [],
      "source": [
        "df4['location'] = df4.location.apply(lambda x : 'other' if x in location_stats_less_than_10 else x)\n",
        "len(df4.location.unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXnB5PfzDXKC"
      },
      "source": [
        "##### **Find per sqft value**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnjt5kf3DXKC"
      },
      "outputs": [],
      "source": [
        "df4['price_per_sqft'] = df4['price']*100000/df4['total_sqft']\n",
        "df4.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pBzv2nrDXKD"
      },
      "source": [
        "#### Ourlier Detection and Removel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YyJwbYUDXKD"
      },
      "source": [
        "compare total sqft with bhk. the below result shows outliers in there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26PgzXuqDXKD"
      },
      "outputs": [],
      "source": [
        "df4[df4.total_sqft/df4.bhk<300].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUGlhJ2xDXKD"
      },
      "outputs": [],
      "source": [
        "print(\"Before Removing outliers\",df4.shape)\n",
        "df5 = df4[~(df4.total_sqft/df4.bhk<300)]\n",
        "print(\"After Removing Outliers\",df5.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1UEEgzMDXKD"
      },
      "outputs": [],
      "source": [
        "df5.price_per_sqft.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GbbEZ7vDXKD"
      },
      "outputs": [],
      "source": [
        "def remove_pps_ourliers(df):\n",
        "    df_out = pd.DataFrame()\n",
        "    for key, subdf in df.groupby('location'):\n",
        "        m = np.mean(subdf.price_per_sqft)\n",
        "        st = np.std(subdf.price_per_sqft)\n",
        "        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft <=(m+st))]\n",
        "        df_out = pd.concat([df_out, reduced_df], ignore_index=True)\n",
        "    return df_out\n",
        "\n",
        "df6 = remove_pps_ourliers(df5)\n",
        "df6.shape\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9JtP0YPDXKD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_scatter_chart (df, location):\n",
        "    bhk2 = df[(df.location==location)& (df.bhk==2)]\n",
        "    bhk3 = df[(df.location==location)& (df.bhk==3)]\n",
        "    plt.rcParams['figure.figsize'] = (15,10)\n",
        "    plt.scatter(bhk2.total_sqft,bhk2.price_per_sqft, color = 'blue', label = '2 BHK', s =50)\n",
        "    plt.scatter(bhk3.total_sqft,bhk3.price_per_sqft, marker= '+',color = 'green', label = '3 BHK', s =50)\n",
        "    plt.xlabel(\"Total Square Feet Area\")\n",
        "    plt.ylabel(\"Price per Square Feet\")\n",
        "    plt.title(location)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_scatter_chart(df6, \"Rajaji Nagar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4m9-PPdEDXKD"
      },
      "outputs": [],
      "source": [
        "df6.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcOL2SvhDXKE"
      },
      "outputs": [],
      "source": [
        "def remove_bhk_outliers(df):\n",
        "    exclude_indices = np.array([])\n",
        "    for location, location_df in df.groupby('location'):\n",
        "        bhk_stats = {}\n",
        "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
        "            bhk_stats[bhk] = {\n",
        "                'mean' : np.mean(bhk_df.price_per_sqft),\n",
        "                'std': np.std(bhk_df.price_per_sqft),\n",
        "                'count' : bhk_df.shape[0]\n",
        "            }\n",
        "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
        "            stats = bhk_stats.get(bhk-1)\n",
        "            if stats and stats['count']>5:\n",
        "                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n",
        "    return df.drop(exclude_indices,axis='index')\n",
        "\n",
        "df7 = remove_bhk_outliers(df6)\n",
        "df7.shape\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2Dfpvr9DXKE"
      },
      "outputs": [],
      "source": [
        "plot_scatter_chart(df7, 'Hebbal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHA4ZH87DXKE"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = (20,10)\n",
        "plt.hist(df7.price_per_sqft, rwidth=0.8)\n",
        "plt.xlabel(\"Price per Square Feet\")\n",
        "plt.ylabel(\"Count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG37rCP2DXKE"
      },
      "outputs": [],
      "source": [
        "df7.bath.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgT-FoMvDXKE"
      },
      "outputs": [],
      "source": [
        "df7[df7.bath>10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeF-jd-eDXKE"
      },
      "outputs": [],
      "source": [
        "plt.hist(df7.bath, rwidth=0.8)\n",
        "plt.xlabel(\"Number of Bathrooms\")\n",
        "plt.ylabel(\"Count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niFl2xABDXKE"
      },
      "outputs": [],
      "source": [
        "df7[df7.bath>df7.bhk+2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HU5WKk83DXKE"
      },
      "outputs": [],
      "source": [
        "df8 = df7[df7.bath<df7.bhk+2]\n",
        "df8.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "modaPjIgDXKE"
      },
      "outputs": [],
      "source": [
        "df9 = df8.drop(['size', 'price_per_sqft'],axis = 'columns')\n",
        "df9.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BMSDRmEDXKE"
      },
      "outputs": [],
      "source": [
        "dummies = pd.get_dummies(df9['location']).astype(int)\n",
        "dummies.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyyCrss1DXKF"
      },
      "outputs": [],
      "source": [
        "df10 = pd.concat([df9,dummies.drop('other', axis=1)], axis=1)\n",
        "df10.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ppreLV7DXKF"
      },
      "outputs": [],
      "source": [
        "df11  = df10.drop('location', axis=1)\n",
        "df11.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkQaIThJDXKF"
      },
      "outputs": [],
      "source": [
        "X = df11.drop('price', axis=1 )\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qioj-6PsDXKF"
      },
      "outputs": [],
      "source": [
        "y = df11.price\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5XBpQk9DXKF"
      },
      "outputs": [],
      "source": [
        "from numpy import test\n",
        "from sklearn.model_selection import train_test_split\n",
        "XTrain,XTest,YTrain,yTrueTest = train_test_split(X,y,test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llySSuPnDXKF"
      },
      "source": [
        "#### Fit to the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpbAOlNxDXKF"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lr_modelObj = LinearRegression()\n",
        "lr_modelObj.fit(XTrain, YTrain)\n",
        "print(lr_modelObj.score(XTest,yTrueTest))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LO8Rlb9BDXKF"
      },
      "outputs": [],
      "source": [
        "yPredict = lr_modelObj.predict(XTest)\n",
        "yPredict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYhNXVHuDXKF"
      },
      "source": [
        "#### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEV5av64DXKG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv = ShuffleSplit(n_splits=5,test_size=0.2,random_state=42)\n",
        "\n",
        "cross_val_score(LinearRegression(),X,y,cv=cv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVwZ2iWSDXKG"
      },
      "source": [
        "#### Grid Search CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMwJYwL7DXKG"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso, LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "def find_best_model(X, y):\n",
        "    algorithms = {\n",
        "        'linear_regression': {\n",
        "            'model': Pipeline([\n",
        "                ('scaler', StandardScaler()),  # Normalize data\n",
        "                ('regressor', LinearRegression())\n",
        "            ]),\n",
        "            'params': {\n",
        "                'regressor__fit_intercept': [True, False],\n",
        "                'regressor__positive': [True, False]\n",
        "            }\n",
        "        },\n",
        "        'lasso': {\n",
        "            'model': Lasso(),\n",
        "            'params': {\n",
        "                'alpha': [1, 2],\n",
        "                'selection': ['random', 'cyclic']\n",
        "            }\n",
        "        },\n",
        "        'decision_tree': {\n",
        "            'model': DecisionTreeRegressor(),\n",
        "            'params': {\n",
        "                'criterion': ['mse', 'friedman_mse'],\n",
        "                'splitter': ['best', 'random']\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    scores = []\n",
        "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
        "    for algor_name, config in algorithms.items():\n",
        "        gs = GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n",
        "        gs.fit(X, y)\n",
        "        scores.append({\n",
        "            'model': algor_name,\n",
        "            'best_score': gs.best_score_,\n",
        "            'best_params': gs.best_params_\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
        "\n",
        "# Example usage (make sure to define X and y first):\n",
        "df = find_best_model(X, y)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSM6NAa1DXKG"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('bangalore_home_prices_model.pickle','wb') as f:\n",
        "    pickle.dump(lr_modelObj,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYEqm_oiDXKG"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "columns = {\n",
        "    'data_columns' : [col.lower() for col in X.columns]\n",
        "}\n",
        "with open('columns.json','w') as f:\n",
        "    f.write(json.dumps(columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eyvdsoLDXKG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}